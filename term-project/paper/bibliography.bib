@article{Thapa2020,
  author   = {Thapa, Ranjita and Zhang, Kai and Snavely, Noah and Belongie, Serge and Khan, Awais},
  title    = {The Plant Pathology Challenge 2020 data set to classify foliar disease of apples},
  journal  = {Applications in Plant Sciences},
  volume   = {8},
  number   = {9},
  pages    = {e11390},
  keywords = {apple orchards, computer vision, convolutional neural network, disease classification, machine learning},
  doi      = {https://doi.org/10.1002/aps3.11390},
  url      = {https://bsapubs.onlinelibrary.wiley.com/doi/abs/10.1002/aps3.11390},
  eprint   = {https://bsapubs.onlinelibrary.wiley.com/doi/pdf/10.1002/aps3.11390},
  abstract = {Premise Apple orchards in the United States are under constant threat from a large number of pathogens and insects. Appropriate and timely deployment of disease management depends on early disease detection. Incorrect and delayed diagnosis can result in either excessive or inadequate use of chemicals, with increased production costs and increased environmental and health impacts. Methods and Results We have manually captured 3651 high-quality, real-life symptom images of multiple apple foliar diseases, with variable illumination, angles, surfaces, and noise. A subset of images, expert-annotated to create a pilot data set for apple scab, cedar apple rust, and healthy leaves, was made available to the Kaggle community for the Plant Pathology Challenge as part of the Fine-Grained Visual Categorization (FGVC) workshop at the 2020 Computer Vision and Pattern Recognition conference (CVPR 2020). Participants were asked to use the image data set to train a machine learning model to classify disease categories and develop an algorithm for disease severity quantification. The top three area under the ROC curve (AUC) values submitted to the private leaderboard were 0.98445, 0.98182, and 0.98089. We also trained an off-the-shelf convolutional neural network on this data for disease classification and achieved 97\% accuracy on a held-out test set. Discussion This data set will contribute toward development and deployment of machine learning–based automated plant disease classification algorithms to ultimately realize fast and accurate disease detection. We will continue to add images to the pilot data set for a larger, more comprehensive expert-annotated data set for future Kaggle competitions and to explore more advanced methods for disease classification and quantification.},
  year     = {2020}
}

@inproceedings{ResNet,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Deep Residual Learning for Image Recognition},
  year      = {2016},
  volume    = {},
  number    = {},
  pages     = {770-778},
  doi       = {10.1109/CVPR.2016.90}
}


@inproceedings{FocalLoss,
  author    = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
  booktitle = {2017 IEEE International Conference on Computer Vision (ICCV)},
  title     = {Focal Loss for Dense Object Detection},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {2999-3007},
  doi       = {10.1109/ICCV.2017.324}
}

@inproceedings{EfficientNet,
  title     = {{E}fficient{N}et: Rethinking Model Scaling for Convolutional Neural Networks},
  author    = {Tan, Mingxing and Le, Quoc},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {6105--6114},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/tan19a/tan19a.pdf},
  url       = {https://proceedings.mlr.press/v97/tan19a.html},
  abstract  = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves stateof-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet (Huang et al., 2018). Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flower (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.}
}

@inproceedings{BagOfTricks,
  author    = {He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
  booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Bag of Tricks for Image Classification with Convolutional Neural Networks},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {558-567},
  doi       = {10.1109/CVPR.2019.00065}
}

@article{fastai,
  author         = {Howard, Jeremy and Gugger, Sylvain},
  title          = {Fastai: A Layered API for Deep Learning},
  journal        = {Information},
  volume         = {11},
  year           = {2020},
  number         = {2},
  article-number = {108},
  url            = {https://www.mdpi.com/2078-2489/11/2/108},
  issn           = {2078-2489},
  abstract       = {fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4&ndash;5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching.},
  doi            = {10.3390/info11020108}
}

@misc{SuperConvergence,
  title  = {Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates},
  author = {Leslie N. Smith and Nicholay Topin},
  year   = {2018},
  url    = {https://openreview.net/forum?id=H1A5ztj3b}
}
